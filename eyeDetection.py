import cv2, time
import mediapipe as mp
import numpy as np
import subprocess

class SystemNotifier:

    @staticmethod
    def notify(message, title="é›†ä¸­åŠ›ãƒ¢ãƒ‹ã‚¿ãƒ¼", subtitle="", sound=True):
        """macOSé€šçŸ¥ã‚»ãƒ³ã‚¿ãƒ¼ã«è¡¨ç¤º"""
        print("é€šçŸ¥ã‚’é€ä¿¡ä¸­...")
        try:
            # AppleScriptã§é€šçŸ¥
            script = f'display notification "{message}" with title "{title}" subtitle "{subtitle}"'
            if sound:
                script += ' sound name "Glass"'
            subprocess.run(['osascript', '-e', script])
            print(f"âœ… é€šçŸ¥é€ä¿¡: {message}")
            return True
        except Exception as e:
            print(f"âŒ é€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    @staticmethod
    def speak(text):
        """éŸ³å£°ã§èª­ã¿ä¸Šã’"""
        subprocess.run(['say', text])

    @staticmethod
    def notify_with_dialog(message, title="è­¦å‘Š"):
        """ãƒ€ã‚¤ã‚¢ãƒ­ã‚°è¡¨ç¤ºï¼ˆç¢ºå®Ÿã«æ°—ã¥ãï¼‰"""
        script = f'display dialog "{message}" with title "{title}" buttons {{"OK"}} default button "OK" with icon caution'
        subprocess.run(['osascript', '-e', script])


# class GazeDetector:
#     def __init__(self):
#         self.mp_face_mesh = mp.solutions.face_mesh
#         self.face_mesh = self.mp_face_mesh.FaceMesh(
#             max_num_faces=1,
#             refine_landmarks=True,  # ç³å­”æ¤œå‡ºã®ãŸã‚å¿…è¦
#             min_detection_confidence=0.5,
#             min_tracking_confidence=0.5
#         )

#         # è™¹å½©ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
#         self.LEFT_IRIS = [474, 475, 476, 477]
#         self.RIGHT_IRIS = [469, 470, 471, 472]

#         # ç›®ã®å‘¨å›²ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
#         self.LEFT_EYE = [33, 133, 160, 159, 158, 144, 145, 153]
#         self.RIGHT_EYE = [362, 263, 387, 386, 385, 380, 374, 373]


#     def get_gaze_direction(self, frame):
#         """è¦–ç·šæ–¹å‘ã‚’åˆ¤å®š"""
#         h, w = frame.shape[:2]
#         rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
#         results = self.face_mesh.process(rgb_frame)
        
#         if not results.multi_face_landmarks:
#             return None, frame

#         face_landmarks = results.multi_face_landmarks[0]
        
#         # å·¦ç›®ã®è™¹å½©ä¸­å¿ƒã‚’è¨ˆç®—
#         left_iris_center = self._get_iris_center(
#             face_landmarks, self.LEFT_IRIS, w, h
#         )

#         # å³ç›®ã®è™¹å½©ä¸­å¿ƒã‚’è¨ˆç®—
#         right_iris_center = self._get_iris_center(
#             face_landmarks, self.RIGHT_IRIS, w, h
#         )

#         # ç›®ã®ä¸­å¿ƒï¼ˆçœ¼çª©ã®ä¸­å¿ƒï¼‰ã‚’è¨ˆç®—
#         left_eye_center = self._get_eye_center(
#             face_landmarks, self.LEFT_EYE, w, h
#         )
#         right_eye_center = self._get_eye_center(
#             face_landmarks, self.RIGHT_EYE, w, h
#         )
        
#         # è™¹å½©ã®ç›¸å¯¾ä½ç½®ã‹ã‚‰è¦–ç·šæ–¹å‘ã‚’åˆ¤å®š
#         left_gaze = self._calculate_gaze_ratio(left_iris_center, left_eye_center)
#         right_gaze = self._calculate_gaze_ratio(right_iris_center, right_eye_center)
        
#         # å¹³å‡ã‚’å–ã‚‹
#         gaze_ratio_x = (left_gaze[0] + right_gaze[0]) / 2
#         gaze_ratio_y = (left_gaze[1] + right_gaze[1]) / 2

#         # è¦–ç·šæ–¹å‘ã‚’åˆ¤å®š
#         direction = self._classify_gaze_direction(gaze_ratio_x, gaze_ratio_y)

#         # å¯è¦–åŒ–
#         annotated_frame = self._draw_gaze(
#             frame, left_iris_center, right_iris_center,
#             left_eye_center, right_eye_center, direction
#         )

#         return {
#             'direction': direction,
#             'gaze_ratio_x': gaze_ratio_x,
#             'gaze_ratio_y': gaze_ratio_y,
#             'left_iris': left_iris_center,
#             'right_iris': right_iris_center,
#         }, annotated_frame

#     def _get_iris_center(self, landmarks, indices, w, h):
#         """è™¹å½©ã®ä¸­å¿ƒåº§æ¨™ã‚’è¨ˆç®—"""
#         points = []
#         for idx in indices:
#             point = landmarks.landmark[idx]
#             points.append([point.x * w, point.y * h])

#         points = np.array(points)
#         center = np.mean(points, axis=0).astype(int)
#         return center

#     def _get_eye_center(self, landmarks, indices, w, h):
#         """ç›®ã®ä¸­å¿ƒåº§æ¨™ã‚’è¨ˆç®—"""
#         points = []
#         for idx in indices:
#             point = landmarks.landmark[idx]
#             points.append([point.x * w, point.y * h])

#         points = np.array(points)
#         center = np.mean(points, axis=0).astype(int)
#         return center

#     def _calculate_gaze_ratio(self, iris_center, eye_center):
#         """è™¹å½©ã®ç›¸å¯¾ä½ç½®ã‚’è¨ˆç®—ï¼ˆ-1.0 ~ 1.0ï¼‰"""
#         # æ°´å¹³æ–¹å‘ã®ã‚ºãƒ¬
#         dx = (iris_center[0] - eye_center[0]) / 30.0  # æ­£è¦åŒ–
#         # å‚ç›´æ–¹å‘ã®ã‚ºãƒ¬
#         dy = (iris_center[1] - eye_center[1]) / 20.0

#         # ã‚¯ãƒªãƒƒãƒ—
#         dx = np.clip(dx, -1.0, 1.0)
#         dy = np.clip(dy, -1.0, 1.0)

#         return (dx, dy)

#     def _classify_gaze_direction(self, ratio_x, ratio_y):
#         """è¦–ç·šæ–¹å‘ã‚’åˆ†é¡"""
#         threshold_x = 0.15
#         threshold_y = 0.15

#         # æ°´å¹³æ–¹å‘
#         if ratio_x < -threshold_x:
#             horizontal = "LEFT"
#         elif ratio_x > threshold_x:
#             horizontal = "RIGHT"
#         else:
#             horizontal = "CENTER"

#         # å‚ç›´æ–¹å‘
#         if ratio_y < -threshold_y:
#             vertical = "UP"
#         elif ratio_y > threshold_y:
#             vertical = "DOWN"
#         else:
#             vertical = "CENTER"

#         # çµ„ã¿åˆã‚ã›
#         if horizontal == "CENTER" and vertical == "CENTER":
#             return "FORWARD"
#         elif horizontal == "CENTER":
#             return vertical
#         elif vertical == "CENTER":
#             return horizontal
#         else:
#             return f"{vertical}_{horizontal}"

#     def _draw_gaze(self, frame, left_iris, right_iris, 
#                     left_eye, right_eye, direction):
#         """è¦–ç·šã®å¯è¦–åŒ–"""
#         # è™¹å½©ã‚’æç”»
#         cv2.circle(frame, tuple(left_iris), 3, (0, 255, 0), -1)
#         cv2.circle(frame, tuple(right_iris), 3, (0, 255, 0), -1)

#         # ç›®ã®ä¸­å¿ƒã‚’æç”»
#         cv2.circle(frame, tuple(left_eye), 2, (255, 0, 0), -1)
#         cv2.circle(frame, tuple(right_eye), 2, (255, 0, 0), -1)

#         # è¦–ç·šãƒ™ã‚¯ãƒˆãƒ«ã‚’æç”»
#         scale = 50
#         left_end = (
#             left_iris[0] + int((left_iris[0] - left_eye[0]) * scale / 30),
#             left_iris[1] + int((left_iris[1] - left_eye[1]) * scale / 20)
#         )
#         right_end = (
#             right_iris[0] + int((right_iris[0] - right_eye[0]) * scale / 30),
#             right_iris[1] + int((right_iris[1] - right_eye[1]) * scale / 20)
#         )

#         cv2.arrowedLine(frame, tuple(left_iris), left_end, (0, 255, 255), 2)
#         cv2.arrowedLine(frame, tuple(right_iris), right_end, (0, 255, 255), 2)

#         # æ–¹å‘ãƒ†ã‚­ã‚¹ãƒˆ
#         cv2.putText(frame, f"Gaze: {direction}", (10, 30),
#                     cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
#         return frame


class GazeMonitorWithNotification:
    def __init__(self, 
                 gaze_threshold=0.2,  # ç›®ç·šãšã‚Œã®é–¾å€¤ï¼ˆèª¿æ•´å¯èƒ½ï¼‰
                 distraction_time=5.0,  # ä½•ç§’åŒã˜ã§ã‚ã‚Œã°é€šçŸ¥ã™ã‚‹ã‹
                 cooldown_time=60.0,    # é€šçŸ¥é–“éš”
                 fps=30):

        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )

        self.fps = fps
        self.distracted_threshold = int(distraction_time * fps)
        self.LEFT_IRIS = [474, 475, 476, 477]
        self.RIGHT_IRIS = [469, 470, 471, 472]
        
        # ç›®ç·šãšã‚Œã®ç›£è¦–è¨­å®š
        self.distracted_frames = 0
        self.last_notification_time = 0
        self.notification_cooldown = 10  # 10ç§’ã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³
        self.notification_count = 0
        # çŠ¶æ…‹ç®¡ç†
        self.distracted_frames = 0
        self.last_notification_time = 0
        self.last_direction = "CENTER"
        # çµ±è¨ˆæƒ…å ±
        self.total_frames = 0
        self.focused_frames = 0
        self.notifier = SystemNotifier()

        print(f"=== åˆæœŸè¨­å®š ===")
        print(f"ç›®ç·šãšã‚Œé–¾å€¤: {gaze_threshold}")
        print(f"é€šçŸ¥ã¾ã§ã®æ™‚é–“: {distraction_time}ç§’")
        print(f"é€šçŸ¥é–“éš”: {cooldown_time}ç§’")
        print("================")

    def detect_gaze(self, frame):
        """è¦–ç·šæ¤œå‡º"""
        h, w = frame.shape[:2]
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.face_mesh.process(rgb)

        if not results.multi_face_landmarks:
            return None, frame

        landmarks = results.multi_face_landmarks[0].landmark

        # è™¹å½©ä¸­å¿ƒã‚’å–å¾—
        left_iris = np.mean([
            [landmarks[i].x * w, landmarks[i].y * h] 
            for i in self.LEFT_IRIS
        ], axis=0).astype(int)

        right_iris = np.mean([
            [landmarks[i].x * w, landmarks[i].y * h] 
            for i in self.RIGHT_IRIS
        ], axis=0).astype(int)

        eyes_center = ((left_iris + right_iris) / 2).astype(int)
        screen_center = np.array([w // 2, h // 2])
        gaze_vector = eyes_center - screen_center

        gaze_x = gaze_vector[0] / (w // 2)
        gaze_y = gaze_vector[1] / (h // 2)

        direction = self._classify_direction(gaze_x, gaze_y)
        is_focused = direction == "CENTER"

        # æç”»
        annotated = self._draw_gaze(frame, left_iris, right_iris, 
                                     eyes_center, direction, is_focused)

        return {
            'direction': direction,
            'is_focused': is_focused,
            'gaze_x': gaze_x,
            'gaze_y': gaze_y,
        }, annotated

    def monitor(self, frame):
        """ç›®ç·šç›£è¦–ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        gaze_info, annotated = self.detect_gaze(frame)

        if gaze_info:
            self.total_frames += 1
            direction = gaze_info['direction']
            is_focused = gaze_info['is_focused']
            # if gaze_info['is_focused']:
            #     self.focused_frames += 1
            #     self.distracted_frames = 0  # ãƒªã‚»ãƒƒãƒˆ
            # else:
            #     self.distracted_frames += 1


            distracted_seconds = self.distracted_frames / self.fps

            # æ–¹å‘å¤‰åŒ–ãŒã‚ã£ãŸå ´åˆ â†’ ã‚«ã‚¦ãƒ³ãƒˆãƒªã‚»ãƒƒãƒˆ
            if direction != self.last_direction:
                self.distracted_frames = 0
                self.last_direction = direction
                print(f"ãƒªã‚»ãƒƒãƒˆ: {direction} | ãƒªã‚»ãƒƒãƒˆ")
            else:
                # åŒã˜æ–¹å‘ãŒç¶šã„ã¦ã„ã‚‹
                self.distracted_frames += 1

            distracted_seconds = self.distracted_frames / self.fps
            print(f"is_focused: {is_focused} | çµŒé: {distracted_seconds:.2f}s")
            print(f"direction: {direction} | çµŒé: {self.last_direction}")
            print(f"2@@distracted_frames: {self.distracted_frames} | distracted_threshold: {int(self.distracted_threshold)}")

            # é›†ä¸­çŠ¶æ…‹ãªã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åŠ ç®—
            if is_focused:
                self.focused_frames += 1

            # åŒã˜æ–¹å‘ãŒä¸€å®šæ™‚é–“ç¶šã„ãŸã‚‰é€šçŸ¥ï¼ˆãŸã ã—10åˆ†ã«1å›ã¾ã§ï¼‰
            if (is_focused == True and 
                int(self.distracted_frames) >= int(self.distracted_threshold)):
                print(f": {self.distracted_frames} | self.distracted_threshold: {self.distracted_threshold}")

                current_time = time.time()
                if current_time - self.last_notification_time > self.notification_cooldown:
                    self._send_notification()
                    print("Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥Â¥")
                    self.last_notification_time = current_time

            # # ç›®ç·šãŒåŒã˜ã§ã‚ã‚‹å ´åˆ
            # if self.distracted_frames >= self.distracted_threshold:
            #     current_time = time.time()
            #     print(f"2@@distracted_threshold: {self.distracted_threshold}")
            #     print(f"2@@distracted_frames: {self.distracted_frames}")

            #     # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æœŸé–“ãŒçµŒéã—ã¦ã„ã‚Œã°é€šçŸ¥
            #     if current_time - self.last_notification_time > self.notification_cooldown:
            #         print(f"2@@ç›®ç·šãšã‚Œãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {self.distracted_frames}")
            #         self._send_notification()
            #         self.last_notification_time = current_time
            #         self.distracted_frames = 0  # ãƒªã‚»ãƒƒãƒˆ

            # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
            focus_rate = (self.focused_frames / self.total_frames * 100) if self.total_frames > 0 else 0
            cv2.putText(annotated, f"Focus Rate: {focus_rate:.1f}%", 
                       (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

            # è­¦å‘Šè¡¨ç¤º
            # if self.distracted_frames > 30:
            #     remaining = self.distracted_threshold - self.distracted_frames
            #     cv2.putText(annotated, f"Warning in: {remaining // 30}s", 
            #                (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

        return annotated
    
    def _classify_direction(self, x, y):
        """è¦–ç·šæ–¹å‘ã‚’åˆ†é¡"""
        threshold = 0.35

        if abs(x) < threshold and abs(y) < threshold:
            return "CENTER"
        elif abs(x) > abs(y):
            return "LEFT" if x < 0 else "RIGHT"
        else:
            return "UP" if y < 0 else "DOWN"
    
    def _draw_gaze(self, frame, left_iris, right_iris, eyes_center, direction, is_focused):
        """è¦–ç·šã®æç”»"""
        annotated = frame.copy()

        # è™¹å½©
        cv2.circle(annotated, tuple(left_iris), 3, (0, 255, 0), -1)
        cv2.circle(annotated, tuple(right_iris), 3, (0, 255, 0), -1)

        # ç›®ã®ä¸­å¿ƒ
        color = (0, 255, 0) if is_focused else (0, 0, 255)
        cv2.circle(annotated, tuple(eyes_center), 5, color, -1)

        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
        status = "FOCUSED" if is_focused else f"DISTRACTED ({direction})"
        cv2.putText(annotated, f"Status: {status}", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

        return annotated

    def _send_notification(self):
        """é€šçŸ¥ã‚’é€ä¿¡ï¼ˆè¤‡æ•°ã®æ–¹æ³•ã‚’è©¦ã™ï¼‰"""
        self.notification_count += 1
        
        # â˜…æ–¹æ³•1: osascripté€šçŸ¥ï¼ˆæœ€å„ªå…ˆï¼‰
        success = self.notifier.notify(
            message="ç›®ç·šãŒãšã‚‰ã—ã¦ãã ã•ã„ï¼ ç”»é¢ã«è¦–ç‚¹ã‚’ã‚¿ã‚¹ã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å†è©•ä¾¡ã—ã¦ãã ã•ã„",
            title="é›†ä¸­åŠ›ãƒ¢ãƒ‹ã‚¿ãƒ¼",
            subtitle=f"{self.notification_count}å›ç›®ã®è­¦å‘Š",
            sound=True
        )
        
        # â˜…æ–¹æ³•2: éŸ³å£°é€šçŸ¥ï¼ˆç¢ºå®Ÿï¼‰
        # self.notifier.speak("ç›®ç·šãŒãšã‚‰ã—ã¦ãã ã•ã„ï¼ç”»é¢ã«è¦–ç‚¹ã‚’ã‚¿ã‚¹ã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å†è©•ä¾¡ã—ã¦ãã ã•ã„")
        
        # â˜…æ–¹æ³•3: ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«å¤§ããè¡¨ç¤º
        print("\n" + "="*50)
        print("ğŸš¨ è­¦å‘Š: ç›®ç·šãŒãšã‚Œã¦ã„ã¾ã™ï¼ ğŸš¨")
        print(f"é€šçŸ¥å›æ•°: {self.notification_count}")
        print("="*50 + "\n")

# ä½¿ç”¨ä¾‹
def main():
    monitor = GazeMonitorWithNotification()
    cap = cv2.VideoCapture(0)
    
    print("=== ç›®ç·šãƒ¢ãƒ‹ã‚¿ãƒ¼é–‹å§‹ ===")
    print("ç›®ç·šãŒ3ç§’ä»¥ä¸Šãšã‚Œã‚‹ã¨é€šçŸ¥ãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
    print("'q'ã‚­ãƒ¼ã§çµ‚äº†")
    print()

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        annotated = monitor.monitor(frame)
        cv2.imshow('Gaze Monitor', annotated)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

    # æœ€çµ‚çµ±è¨ˆ
    if monitor.total_frames > 0:
        focus_rate = monitor.focused_frames / monitor.total_frames * 100
        print(f"\n=== çµ±è¨ˆæƒ…å ± ===")
        print(f"ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {monitor.total_frames}")
        print(f"é›†ä¸­ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {monitor.focused_frames}")
        print(f"é›†ä¸­ç‡: {focus_rate:.1f}%")

    # detector = GazeDetector()
    # cap = cv2.VideoCapture(0)
    # print("Press 'q' to quit.")

    # while cap.isOpened():
    #     ret, frame = cap.read()
    #     if not ret:
    #         break
        
    #     gaze_info, annotated_frame = detector.get_gaze_direction(frame)
        
    #     if gaze_info:
    #         print(f"Direction: {gaze_info['direction']}, "
    #               f"Ratio X: {gaze_info['gaze_ratio_x']:.2f}, "
    #               f"Ratio Y: {gaze_info['gaze_ratio_y']:.2f}")
        
    #     cv2.imshow('Gaze Detection', annotated_frame)
        
    #     if cv2.waitKey(1) & 0xFF == ord('q'):
    #         break
    
    # cap.release()
    # cv2.destroyAllWindows()


if __name__ == "__main__":
    main()



